# ロジスティック回帰

## 1 線形回帰との違い
線形回帰という手法をすでに学びました。これから学ぶロジスティック回帰は同じ貝木という名前がついていますが線形回帰とは違うわけですねどこが違うのでしょうか。
一言で言えばロジスティック回帰では数値ではなく２群判別を行う回帰分析だという違いがあります。
線形回帰では説明変数と目的変数がともに数値でした。与えられたデータから、それらの関係を分析して、説明変数から目的変数を線形の関係で推定をする関係式を求めるのが線形回帰分析の目的でした。
別の言い方をすれば、もしいくつかの事項から別の事項が比例の関係でもたらされているのはどのような比例関係であるかを、線形回帰によって求めることができたのです。

ロジスティック回帰は同じように説明変数から、結果を求めますが、結果は連続の値ではなく２群判別です。つまり0か1であったり黒か白であったりそういう二通りの値を判別します。

とはいえ目的変数を例えば0と1という２値の数値として、線形回帰を行うこともできますね。しかしそのような方法はよい方法ではない。
第一に、データとして２値しかないのは本当に２値なのではなく、なにかしらの数値が結果として得られた後で、２値に置き換えられているという現象であることが多い。
たとえば、ガラスに石をあてて割れるかとうか。様々な理由でガラスにかかる力が変わるでしょう。そしてそれがある値を超えると割れる、と考えられます。
割れた、割れないというデータには、どのくらいの力がかかったかという情報が抜け落ちている。
なので、線形回帰のように、0,1と説明変数の相関をとっても、説明変数との関係はうまく分析できない、という理由があります。
別のいいかたをすれば、ロジスティック解析では与えられたデータにおける説明変数と結果の間には隠された中間層がある、という言い方もできます。その中間層を推定しながら関係式を導く必要かあるから、それにあった分析が必要です。
また、当然ロジスティック回帰では線形回帰よりもはるかに多くのデータを必要とし、誤りも多くなります。ですから、ロジスティック回帰では、目的は２群判別を正答する、というよりは確率分布を求めることが目的となります。
さらに、多群判別、つまり2群以上の判別には、ロジスティック回帰は向きません。

それではロジスティック回帰の方法と実例を見てみましょう。

## 2 ロジスティック回帰の手法

例によってロジスティック回帰もRのライブラリ関数の中に実現されているので分析方法を全く知らなくても関数を呼べば簡単に求めることができます。

しかし簡単にその手法を見ておきましょう。
回帰分析では目的変数を線形の式で表しました。

$Y = a X + b$

ロジスティック回帰では目的変数をこのような式であらわします。

$p = \frac{1}{1 + e ^ {- (aX + b)}}$



こうするとうまい具合に最適なパラメーターを求める方法が見つかるのですね。

この式は, {0, 1} という2値の近似というよりは、{a, b} という2群のどちらかに属する「確率」を表してる、と考えることもできます。

別の言い方をすれば線形回帰では、目的変数と予想値の誤差を最小にするように回帰直線を選んだわけですが、ロジスティック回帰では確率を求めているので2群判別の正解率を上げるようにパラメータを調整するのだ、と考えることができます。

そこの違いだけで、後は数学的にはそのような最適解を求める、という点は同じです。

## 3 ロジスティック回帰における注意

ロジスティック回帰でも分析において注意すべき点があります。

まずいくつかの変数のうち一つの変数で完全に予測ができてしまうという場合があります。この場合分析結果が適切でなくなる場合があるので警告が出ます。

この現象は線形分析で目的変数が説明変数の一部で完全に予想できてしまう場合と仕組み上は同じですね。つまり一つの変数で結果が予想できてしまうと他の変数が結果にどう影響するかという計算のところで計算上の問題が生じるわけです。

この現象は、線形回帰の場合と同様におこりがちででしょう。

何かの値を予想したい、と思えばついいろいろな説明変数を導入してしまします。

多くの説明変数を導入すれば、それによって完全に結果を説明できてしまます。

ですから、ロジスティック回帰においても、データ数にたいして、説明変数をむやみに多くしてたまたまよい結果を得ても、それは意味のない結果である、ということになります。

データ数に対し適切な説明変数の数で、分析を行う必要があるわけです。

もちろん実はたくさんの説明変数を試した結果、よいものだけを選ぶ、ということによっても意味がない結果を出してしまう危険はありますね。

## 4 データ数と説明変数のバランスはどうとるか

あるデータ数があった場合にどの程度の説明変数があると問題がおきるか。だいたいのあたりをつけられるようにしておくとよいでしょう。

まず、あたりまえの場合を考えてみます。

256 個のデータについて8個の変数があれば、完全に結果が示せてしまう可能性があることはわかりますか?

一方で、たとえ4個のデータであっても何個の変数があればあらわせるかは、確実にはいえません。

しかし16通りのパターンしかないので、16個の変数があって、それらがすべて異なるパターンであれば、そのうちの一個が当てはまる可能性は高そうです。

そして実際には2個, 3個の組み合わせもできるから、一般的に n 個のデータであれば 2の n乗の平方根程度の数の変数で、結果が表せてしまう可能性は高いでしょう。

逆にいえばその程度ｎ変数の中からロジスティック回帰で正答率の高い結果が出たとしても、それは十分な数のランダムな選択の中からたまたま引き当てたにすぎない可能性が高いといえますね。

256 個のデータがあれば、10程度の変数でそのような問題がおきる可能性は少ない、と考えられるでしょう。

もちろんこうした見積もりはかなりざっくりとしたもので、データの性質によって状況は大きくことなります。たとえばある変数に沿ってある時点からは0から1になる傾向が顕著であれば、説明変数が過剰になる率はずっと高くなります。

このように、説明変数のバランスの問題を理解した上で、研究計画をたてる必要があります。



線形回帰の場合と同じように、ロジ



