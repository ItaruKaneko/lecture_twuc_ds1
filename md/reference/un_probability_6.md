# ランダムフォレストとアンサンブル学習

アンサンブル学習とその代表的手法であるランダムフォレストを説明します。

アンサンブル学習は学習による分類方法の一つです。
様々な学習分類方法の中でも、アンサンブル学習は最も性能のよい方法です。

## 1. 決定木

ランダムフォレストを説明する前に決定木の説明が必要です。
すでに様々な識別方法を紹介してきましたが、
1段階の単純な識別では様々な分類の形には対応できないことがあります。

たとえば、でこぼこに入り組んだ領域を線形識別で分類することは困難です。

そこで識別を何段も分けて行なっていくのが決定木です。

段階を踏んで、一度分類した領域の中でさらに分類していけば、直線的ではないでこぼこの境界の分類も可能になります。
さらに細分化することも可能としておけ

線形識別では直線的な境界での識別しかできないが、、二段階にすれば一度区分類した中をさらに二つの領域に分けることができます。さらに細分化することも可能としておけば、原理的にはあらゆる形状の領域を区分することができます。

この決定木に従った判別を学習するには、
まず最も大きな領域を分割し、
その領域の中で誤識別誤った識別を表示するデータを選んで、
さらにその領域の中を分割するということを、
繰り返していけばいい。

決定木のアルゴリズムではそのような学習を自動的に行って、
何段階の指揮科の識別からなる決定木を自動的に構築します。

しかし決定木にも欠点があります。

与えられたデータで決定木を作っていくと、
エラーになったデータがエラーにならないよう識別をするので、
これを繰り返していくとかならず全問正解になってしまいます。

学習データに関しては100%正しい識別ができるようになります。
しかしこれは以前から何度も登場した、いわゆる「過剰適合」となります。

途中どんな誤った識別をしても、その後の段で補正できるので、
意味のない識別をしてしまう。

決定木では過剰適合の問題が起きやすいと言えます。

## 2. ランダムフォレスト
そこで単純な決定よりも眼瞼で高い精度をもたらす方法がランダムフォレストという方法です。
フォレストというのは森を表します。
つまり木がいっぱいある状態を意味しています。
ランダムフォレストの木とは決定着のことで、文字通り決定木をたくさんつくって森のようにするのがランダムフォレストです。

ランダムフォレストでは学習すべきデータからランダムに一部を取り出してそれによって決定木を作ります。

学習データを選んでは決定木を作り選んではまた別の決定木を作るこれを繰り返します。すると選ばれた学習データによって様々な識別の効果を持つ決定が無数に作られるわけです。

こうして作られた無数の決定を全て並行して動作させて、
その多数決を取るという方法で全体の判別をする。
これがランダムフォレストです。

こんな方法がうまくいくのでしょうか?
単純な識別器を多数集めるよりも、現象にあった複雑な予測モデルを一つ精密にトレーニングした方が正確な答えが得られるように思われます。

実際モデルが複雑で、モデルがあってさえいれば制度よく予測ができる場合は、精密な識別器を一つ使う方が正確な答えが得られると思います。

しかし、経験的にはランダムフォレストは多くの場合、よい性能を発揮するのです。

人間が相談する時にも3人寄れば文殊の知恵という言葉がありますが、ランダムフォレストは、単純な低性能の判別器を多数組み合わせます。

まさにその場合も3人寄れば文殊の知恵、という原理が発揮されるのです。
大変おもしろい性質ですね。

## 3. アンサンブル学習
そしてアンサンブル学習ですがこのように多数の低性能な学習器を用いて全体として高い性能を達成する方式が様々開発されています。そのような方式を総称して多くの識別機ちょうど音楽の合奏のように働くのでアンサンブル学習と呼んでいるのです。
このアンサンブル学習の進歩はやがて人工知能やニューラルはネットワークの仕組みと結合してさらに高性能のデータ処理の方法に発展していきます。アンサンブル学習は人工知能などの処理過程の一部として使われますしまたアンサンブル学習の多数の識別機を並行して動作させるという原理は人工知能でも広く使われています。
