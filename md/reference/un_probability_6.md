# ランダムフォレストとアンサンブル学習

アンサンブル学習とその代表的手法であるランダムフォレストを説明します。

ランダムフォレストはアンサンブル学習と総称される教師付学習をつかった分離方法の一つです。
様々な学習分類方法の中でも、ランダムフォレストは最も性能のよい方法の一つです。

## 1. 決定木

ランダムフォレストを説明する前に決定木の説明が必要です。
すでに様々な判別方法を紹介してきましたが、
1段階の単純な判別では様々な分類の形には対応できないことがあります。

たとえば、でこぼこに入り組んだ領域を線形判別で分類することは困難です。

そこでは、判別を何段も重ねて行います。これが決定木です。

段階を踏んで、一度分類した領域の中でさらに分類していけば、直線的ではないでこぼこの境界の分類も可能になります。

線形判別では直線的な境界での判別しかできないが、、二段階にすれば一度区分類した中をさらに二つの領域に分けることができます。さらに細分化することも可能としておけば、原理的にはあらゆる形状の領域を区分することができます。

この決定木に従った判別を学習するには、
まず最も大きな領域を分割し、
その領域の中で判別を誤った判別を表示するデータを選んで
さらにその領域の中を分割するということを、
繰り返していけばいい。

決定木のアルゴリズムではそのような学習を自動的に行って、
何段階の判別からなる決定木を自動的に構築します。

しかし決定木にも欠点があります。

与えられたデータで決定木を作っていくと、
エラーになったデータがエラーにならないよう判別をするので、
これを繰り返していくとかならず全問正解になってしまいます。

学習データに関しては100%正しい判別ができるようになります。
しかしこれは以前から何度も登場した、いわゆる「過剰適合」となります。

途中どんな誤った判別をしても、その後の段で補正できるので、
意味のない判別をしてしまう。

決定木では過剰適合の問題が起きやすいと言えます。

## 2. ランダムフォレスト
そこで単純な決定よりも頑健で高い精度をもたらす方法がランダムフォレストという方法です。

フォレストというのは森を表します。
つまり木がいっぱいある状態を意味しています。
ランダムフォレストの木とは決定木のことで、文字通り決定木をたくさんつくって森のようにするのがランダムフォレストです。

ランダムフォレストでは学習すべきデータからランダムに一部を取り出してそれによって決定木を作ります。

学習データを選んでは決定木を作り選んではまた別の決定木を作るこれを繰り返します。すると選ばれた学習データによって様々な判別の効果を持つ決定が無数に作られるわけです。

こうして作られた無数の決定木を全て並行して動作させて、
その多数決を取るという方法で全体の判別をする。
これがランダムフォレストです。

こんな方法がうまくいくのでしょうか?
単純な判別器を多数集めるよりも、精密な判別器を一つ精密作った方が正確な答えが得られるのではないか?

実際数学的に厳密に解けるような問題であれば、精密な計算を行う判別器を一つ作る方が良い性能が得られます。

しかし、大多数のよくある問題ならば、経験的にはランダムフォレストはよい性能を発揮するのです。

人間が相談する時にも3人寄れば文殊の知恵という言葉がありますが、ランダムフォレストは、単純な低性能の判別器を多数組み合わせます。

まさにその場合も3人寄れば文殊の知恵、という原理が発揮されるのです。
大変おもしろい性質ですね。

## 3. アンサンブル学習
そしてアンサンブル学習ですがこのように多数の低性能な判別器を用いて全体として高い性能を達成する方式が様々開発されています。そのような方式を総称して多くの判別機ちょうど音楽の合奏のように働くのでアンサンブル学習と呼んでいるのです。
このアンサンブル学習の進歩はやがて人工知能やニューラルはネットワークの仕組みと結合してさらに高性能のデータ処理の方法に発展していきます。アンサンブル学習は人工知能などの処理過程の一部として使われますしまたアンサンブル学習の多数の判別機を並行して動作させるという原理は人工知能でも広く使われています。
