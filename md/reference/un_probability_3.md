# 線形判別分析

判別分析とは、データをいくつかに判別することを意味します。
たとえば料品と不良品を判別したり、ひよこや魚のオスとメスを判別したり、
テストの結果で合格すべき人と不合格にすべき人を判別したいとします。

その際、基準として、正解となるデータを与えます。
まず判別の正解の例をいくつか与えることにより、判別の基準を与え、
それによって判別したいデータの判別を行うというわけです。

このように、正解を与えることで、判別の基準を与える方法は、
「機械学習」で行う方法と同じです。実際データサイエンスの判別分析と
機械学習といわれているもののなかの単純な方式は共通のものです。

ただし機械学習の理論が発展してからは、より複雑な判別方法が発達しています。

まず、もっとも単純な判別分析から学んでいきましょう。

線形判別分析は、線形の判別関数を用いてデータを判別する方法です。

線形の判別関数とは、観測値を重みづけ加算した関数です。
つまり観測値の線形結合であらわされています。

そして判別関数の値が判別すべきどちらのグループに近いかで、
判別を行います。

この重みを、判別の性能がもっともよくなるように調整します。

どのように重みを調整すればよいでしょうか。

判別欠課がよくなるような重みの
この判別関数は線形結合の係数によって様々にかわります。

この判別関数を、識別に最適なように調整して、識別を行うのが、線形判別分析です。

線形判別分析では、したがって、説明変数の加重平均を求め、その値がある値以上か以下かで
判別を行うことになるわけです。

線形回帰分析と線形判別分析の式はよく似ています。
どちらも結果を説明変数の線形関数としてあらわします。つまり説明変数
に係数をかけて足し合わせたもので結果を表す、という点は共通です。
では回帰分析と判別分析は何が異なるでしょう。

回帰分析の目的変数は、「量的」な変数です。たとえば、身長とウエストサイズで
体重を推定するとすると、体重は「量的」な変数です。

一方判別分析は、「質的」な結果を求めます。たとえば、同じ身長とウエストサイズ
で「性別」を判別しようとした場合、「性別」は量ではありません。

すると、目的とする関数が変わってきます。

回帰分析では、量を推定しますから、目標となるのは「誤差」の量になります。
つまり、予測が正確に一致することはないが、値が近いほど、そして値が少しずつ
真の値と異なってる場合はその「合計」が小さいほどよい予測であるとして、
分析を行います。

すでに誤差を単純に合計するのでｈなく、誤差の２乗の合計を最小にするように
誤差の最小かを行うということは説明しました。こうすることで、誤差の
エネルギーを最小にする、詳しくはここでは説明しませんが、数学的には
たいへん都合がよく、また、望ましい予測ができるわけです。

判別分析では、誤差の大きさはあまり意味を持ちません。もし判別が間違えて
いれば、わずかの誤差で誤判別しても、大きな差であってもあまり関係は
ありません。

線形判別分析における判別関数の求め方は、回帰分析の式とは異なってくるのはそのためです。

線形判別分析でサンプルが正規分布をしている場合には、
各グループの平均と分散から判別分析を求めることになります。

# マハラノビス距離



データによっては


多重共線性(multicollinearity)

分散拡大係数

決定境界

ホールドアウト

交差検証(Cross Varidation)

k分割交差検証(k-Fold Cross Varidation)

LOOCV (Leave-One-Out Cross Varidation)

混同行列


基礎的な用語
中点

散布図

可視化

誤識別率

精度

再現性

正確度




射影